The n-body simulations are relevant for many fields of science, from planet and galaxy interactions all the way down to molecular dynamics. The computational challenge comes from the fact that all bodies have some effect on all the others. The effect comes from the gravitational pull each body has on the others, the force one body of mass $m_1$ has on another of mass $m_2$ depends on the distance between each body $r$ and the gravitational constant $G$. The formula is the following:
\[\boldsymbol{\norm{F}} = G\frac{m_1m_2}{r^2}\]
where $G=\SI{6.674e-11}{Nm^{2}kg^{-2}}$. The direction of the force is given by the center of masses of the objects in the following way, where $p_1$ and $p_2$ are the positions of both masses. 
\begin{align*}
F_x &= \norm{\boldsymbol{F}}\frac{p_{2,x}-p_{1,x}}{r}\\
F_y &= \norm{\boldsymbol{F}}\frac{p_{2,y}-p_{1,y}}{r}
\end{align*}
\subsection{Complexity}
A classical brute-force approach to this problem has a complexity of $\boldsymbol{\mathcal{O}(n^2)}$, where $n$ is the number of bodies in the system. This will rapidly become unbearable, since for 1000 bodies the calculations take the order of one second on a laptop. Since this problem is time dependent, the calculations must be performed at each time step, hence the importance of having an efficient application to perform the body interactions is obvious. The computation of the interactions at each step is straight forward, using two loops, the force on each body induced by the other bodies is calculated.\\
One well-known solution to this problem is the Barnes-Hut algorithm. This method calculates the forces acting between one body, and a group of bodies represented by the average of the group's masses and positions. With this algorithm, the complexity is reduced to $\boldsymbol{\mathcal{O}(nlogn)}$. In this case, the world (i.e. collection of bodies) is stored in a structure called ``quad-tree'', where each node stores the average of the body's positions and masses. At the leaves there is either a body if it fits into the quadrant, or nothing if no body is present. To calculate the interactions between all bodies, we traverse all bodies, and based on a distance criteria we either calculate the interaction with the exact body or the interaction with an ``averaged body''. 

\subsection{Computations vs communications}
For a simple brute-force approach, the computations follow $\mathcal{O}(n^2)$ at each time step. To guarantee correct results, the acceleration, velocity and position of all bodies must be updated on each node in a synchronized manner, hence one node cannot move forward in time until all forces have been calculated. Once the new positions are calculated for all bodies on each node, these updated positions must be broadcast to all other nodes so they can continue the compuations at the next time step. Therefore the communication complexity is $\mathcal{O}(n)$, since the positions of the bodies must be passed around between nodes. The ratio of computations to communications can be approximated as $\mathcal{O}(n)$ for the parallel brute-force approach.\\
For Barnes-Hut's algorithm, this ratio is slightly different. The choice is made to rebuild the quad-tree from scratch at each time iteration, this makes the implementation much easier and the time taken is not significant compared to the computation time. With this in mind, the communications are the same as for the brute-force approach, since at each time step the positions and velocities of each body must be passed to all compute nodes again. Therefore the calculations are in $\mathcal{O}(nlogn)$ and the communications are $\mathcal{O}(n)$, hence a ratio of $\mathcal{O}(logn)$.
\subsection{Amdahl's Law}
Since the goal is the analyse the parallel aspects of the problem, the time taken to write the results to a file at each time step are not taken into account. This part is significant and limits the speedup values to very poor ones. In both cases, the initial data is stored in a file which must be read to get the initial positions and velocities. The time taken to read this data is also ignored.
\paragraph{Brute-Force} For the brute-force approach, since the data is stored in arrays, very little pre-processing is required. The fraction of non-parallelizable code is close to nothing, as the initial time during which the data is loaded from a file is neglected. Table \ref{tab:amdahl} contains the values required to use Amdahl's law for predicting the speedup. Since there is no calculation performed serially, only the communication time is relevant. In Figure \ref{fig:amdahl}, the speedups are shown for two different problem sizes, but it is apparent that such large speedups for large numbers of nodes is not feasible.

\paragraph{Quad-Tree}
For a quad-tree method, the serial part is still only reading the initial data. Since each node builds its own quad-tree, the serial part remains only reading the initial data. Hence the initial communication will be the distribution of the initial positions and velocities. The measurements which are performed for the brute-force approach are still valid, as the difference happens during the time iterations. Except that now the computation time is significantly faster, hence the fraction of serial code is larger.  With this regard, the optimistic upperbound will not be as high as previously since the computations are in $\mathcal{O}(nlogn)$ (and not $\mathcal{O}(n^2)$) , but the communications are the same. Here the limitation of Amdahl's law is evident. Since each compute-node builds the tree, this time is not counted in Amdahl's law but it is the limiting factor when the number of compute-nodes becomes large.

\begin{table}[H]
\centering
\begin{tabular}{l|ccccc}
Algorithm                    & \# bodies & Serial total time [s] & Serial cal. [s] & Initial comm. [s] & Fraction \\
\hline\multirow{2}{*}{Brute-force} & $10^5$    & 450  & - & 0.006 &$1.33\cdot 10^{-5}$\\
                             & $10^6$    & 45'000& - & 0.06  &$1.33\cdot 10^{-6}$\\     
\multirow{2}{*}{Barnes-Hut}  & $10^5$    & 8.5  & - & 0.006 &$7.06\cdot 10^{-4}$\\
                             & $10^6$    & 100  & - & 0.06  &$6.00\cdot 10^{-4}$\\
\end{tabular}
\caption{Measurements for Amdahl's estimation of the speedups. Since the time taken to read the initial data from a file is not considered, there is not any serial calculation. Only the time taken for the initial communication is relevant.}
\label{tab:amdahl}
\end{table}

\begin{figure}[H]
\input{../figures/amdahl_bf.tex}
\caption{Amdahl's estimation for the upper bound of the speedup, for both the brute-force approach and the quad-tree method. These are estimations based on some simple timings on a serial implementation. It is already apparent that these values are too high. The fact that with the Barnes-Hut algorithm the speedup is still quasi-linear using 2'000 nodes emphasizes that these values are not realistic.}
\label{fig:amdahl}
\end{figure}

