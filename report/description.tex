The n-body simulations are relevant for many fields of science, from planet and galaxy interactions all the way down to molecular dynamics. The computational challenge comes from the fact that all bodies have some effect on all the others. The effect comes from the gravitational pull each body has on the others, the force one body of mass $m_1$ has on another of mass $m_2$ depends on the distance between each body $r$ and the gravitational constant $G$. The formula is the following:
\[\boldsymbol{\norm{F}} = G\frac{m_1m_2}{r^2}\]
where $G=\SI{6.674e-11}{Nm^{2}kg^{-2}}$. The direction of the force is given by the center of masses of the objects in the following way, where $p_1$ and $p_2$ are the positions of both masses. 
\begin{align*}
F_x &= \norm{\boldsymbol{F}}\frac{p_{2,x}-p_{1,x}}{r}\\
F_y &= \norm{\boldsymbol{F}}\frac{p_{2,y}-p_{1,y}}{r}
\end{align*}
\subsection{Complexity}
A classical brute-force approach to this problem has a complexity of $\boldsymbol{\mathcal{O}(n^2)}$, where $n$ is the number of bodies in the system. This will rapidly become unbearable, since for 1000 bodies the calculations take the order of one second on a laptop. Since this problem is time dependant, the calculations must be performed at each time step, hence the importance of having a parallel application to perform the body interactions is obvious. The copmutation of the interactions at each step is straight forward, using two loops the force on each body induced by the other bodies is calculated.\\
One well-known solution to this problem is the Barnes-Hut algorithm. This method calculates the forces acting between one body, and a group of bodies represented by the average of the group's masses and positions. With this algorithm, the complexity is reduced to $\boldsymbol{\mathcal{O}(nlogn)}$. In this case, the world (i.e. collection of bodies) is stored in a structure called ``quad-tree'', where each node stores the average of the bodie's positions and masses. At the leaves there is either a body if it fits into the quadrant, or nothing if no body is present. To calculate the interactions between all bodies, we traverse all bodies, and based on a distance criteria we either calculate the interaction with the exact body or the interaction with an ``averaged body''. 

\subsection{Computations vs communications}
For a simple brut-force approach, the computations follow $\mathcal{O}(n^2)$ at each time step. To guarantee correct results, the acceleration, velocity and position of all bodies must be updated in a synchronized manner, hence one cannot move forward in time until all forces have been calculated. Once the new positions are calculated for all bodies on each node, these updated positions must be broadcast to all other nodes so they can continue the compuations at the next time step. Therefore the communication complexity is $\mathcal{O}(n)$, since the positions of the bodies must be passed around between nodes. The ratio of computations to communications can be approximated as $\mathcal{O}(n)$ for the parallel brute-force approach.\\
For Barnes-Hut's algorithm, this ratio remains the same. The choice is made to rebuild the quad-tree from scratch at each time iteration, this makes the implementation much easier and the time taken is not significant compared to the computation time. With this in mind, the communications are the same as for the brute-force approach, since at each time step the positions and velocities of each body must be passed to all compute nodes again. Therefore the calculations are in $\mathcal{O}(nlogn)$ and the communications are $\mathcal{O}(n)$.
\subsection{Amdahl's Law}
Since the goal is the analyse the parallel aspects of the problem, the time taken to write the results to a file at each time step are not taken into account. This part is significant and limits the speedup values to very poor ones. In both cases, the initial data is stored in a file which must be read to get the initial positions and velocities.  
\paragraph{Brute-Force} For the brut force approach, since the data is stored in arrays, very little pre-processing is required. The fraction of non-parallelizable code is very low, it is only loading the data from a file. XXX PERFORM CORECT MESAURMENETS Some quick measurements give a fraction $f=0.005$ as the serial part. Hence the optimistic upper bound for the speed can be calculated and plotted. For the improved estimation, the communication fraction can be estimated to $f_{comm} = 0.015$, which takes into account the time to distribute the inital situation to the nodes. The data which must be distributed is the mass, initial velocities and positions to all nodes. Hence the new ``realistic'' speedup graph is shown below, Figure \ref{fig:th_su}. This speedup graph is still far too optimistic as it does not take into account the communication at each time step.\\

\paragraph{Quad-Tree}
For a quad-tree method, the serial part is still only reading the initial data. Since each node builds its own quad-tree, the serial part remains only reading the initial data. Hence the initial communication will be the distribution of the initial positions and velocities. The measurements which are performed for the brute-force approach are still valid, as the difference happens during the time iterations. Except that now the computation time is significantly faster, hence the fraction of serial code is larger.  With this regard, the optmistic upperbound will not be as high as previously since the computations are in $\mathcal{O}(nlogn)$ (and not $\mathcal{O}(n^2)$) , but the communications are the same. Figure \ref{fig:th_su} shows a first estimate of the speedup, based on the measurements of the serial execution time.\\

\begin{figure}[H]
\input{../figures/amdahl_bf.tex}
\caption{Theoretical speedup chart for both the brut-force approach and the quad-tree method. These are estimations based on some simple timings on a serial implementation.}
\label{fig:th_su}
\end{figure}

%f = 0.001 hence max is very high.
%Required communicatpon: positions swapped times n_procs. gigabit eternet: 125MB/s latency: 0.125ms
%fcomm = 0.015           ftot = 0.001 hence plot theoretical best and lower best.

